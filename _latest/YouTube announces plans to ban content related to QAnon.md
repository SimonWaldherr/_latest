--- 
extends: _layouts.post 
section: content 
image: https://i.guim.co.uk/img/media/c5b2359409dee9dc3b093a7be009f0b0040d155c/0_244_3600_2160/master/3600.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=922be57dfed1ffe7ce2ef570b80c4bea 
title: > 
  YouTube announces plans to ban content related to QAnon 
description: > 
  YouTube said Thursday it will begin banning some content related to QAnon, a massive and baseless online conspiracy theory movement that has been tied to real-life violence.YouTube will instead focus on content that targets an individual or groups with conspiracy theories related to QAnon.YouTube is the latest platform to crack down on QAnon content ahead of the 3 November presidential election.Facebook announced on 6 October that it would ban all pages, groups, and accounts related to the promotion of QAnon.In July, Twitter announced a broad crackdown on QAnon content, kicking 7,000 QAnon accounts off the platform and promising to stop promoting or recommending QAnon. 
date: 1602795722.233455 
--- 
YouTube said Thursday it will begin banning some content related to QAnon, a massive and baseless online conspiracy theory movement that has been tied to real-life violence.

The online video service said in a blogpost it would remove conspiracy theory content used to justify real-world violence from its network. It comes after Facebook announced similar but more extensive measures, banning all QAnon content outright.

YouTube will instead focus on content that targets an individual or groups with conspiracy theories related to QAnon. It will begin enforcing these expanded hate and harassment policies immediately and would “ramp up” in the weeks to come.

“One example would be content that threatens or harasses someone by suggesting they are complicit in one of these harmful conspiracies, such as QAnon or Pizzagate,” the announcement said.

The company argued it had taken previous steps to limit such content, including limiting the reach of harmful misinformation through its recommendations system, but admitted “there’s even more we can do to address certain conspiracy theories that are used to justify real-world violence, like QAnon”.

YouTube is the latest platform to crack down on QAnon content ahead of the 3 November presidential election. Facebook announced on 6 October that it would ban all pages, groups, and accounts related to the promotion of QAnon.

In July, Twitter announced a broad crackdown on QAnon content, kicking 7,000 QAnon accounts off the platform and promising to stop promoting or recommending QAnon. Twitter did not ban QAnon from its site entirely, but said it would no longer make QAnon tweets or accounts visible in searches or recommendations.

But both platforms still struggle to tamp down on the pervasive conspiracy theory. A report from the Associated Press found that, in recent weeks, content related to the mass delusion still spreads on the social media platform. The AP discovered more than a dozen popular QAnon accounts on Twitter that collectively maintain a following of nearly 1.5 million users, almost all of which were recommended to users who followed other QAnon accounts.

QAnon adherents believe that Donald Trump is trying to save the world from a cabal of satanic pedophiles that includes Democrats, Hollywood elites and “deep state” allies. The conspiracy theory’s narrative includes centuries-old antisemitic tropes, such as the belief that the cabal is harvesting blood from abused children.

The mass delusion has been tied to a number of violent events. In 2016, a believer in a QAnon-adjacent theory known as PizzaGate traveled to Washington DC and fired shots into a pizza restaurant he believed was housing a child sex ring.

Experts call these extreme, baseless claims “an incitement to violence”. The movement was named by the FBI as a potential instigator of domestic terrorism.

Reuters contributed to this report.