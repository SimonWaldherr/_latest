--- 
extends: _layouts.post 
section: content 
image: https://cdn.businessinsider.es/sites/navi.axelspringer.es/public/styles/1200/public/media/image/2020/10/sugerencias-autocompletado-google-busqueda-vacunas-2096985.jpg?itok=nz4WyNOH 
title: > 
  Google sugiere que las vacunas son malas, el nazismo respetaba los derechos humanos o secuestrar niños es gracioso 
description: > 
  '[...] son malas' es la primera búsqueda que Google te sugerirá hacer para una consulta que empieza por 'las vacunas son '.Los filtros que Google utiliza para evitar que el autocompletado muestre lo que el usuario no debería verPartiendo de la premisa de que sus recomendaciones no son siempre perfectas, Google es consciente de que puede haber usuarios que interpreten las predicciones del autocompletado como afirmaciones categóricas sobre hechos u opiniones.Este filtro actúa antes de que la sugerencia pase a formar parte de la lista de autocompletar.En caso de que el primer mecanismo falle, existen equipos humanos que se encargan de retirar aquellas sugerencias de búsqueda que, estando ya en línea, hayan sido marcadas como potencialmente peligrosas.Claro que, para eso, primero es necesario que un usuario denuncie la predicción en cuestión. 
date: 1602310301.958944 
--- 
Prueba a entrar en Google.es desde el modo incógnito de tu navegador, sitúa el ratón sobre la caja de búsqueda y comienza a escribir: 'las vacunas son ', dejando un espacio para que el buscador te sugiera términos relacionados con tu consulta.

'[...] son malas' es la primera búsqueda que Google te sugerirá hacer para una consulta que empieza por 'las vacunas son '. ¿'Las vacunas son malas'? ¿Así, tan categórico, como primera sugerencia de búsqueda? ¿Será una excepción?

Mucho más lejos de la realidad, para la búsqueda 'el nazismo fue ', Google sugiere en segundo lugar que 'el nazismo fue respetuoso de los derechos humanos'; si se realiza una consulta acerca de 'secuestrar niños es ', Google decide que la búsqueda que mejor se adapta a la pregunta pasa por 'secuestrar niños es gracioso' (además, no hay otra opción: o es gracioso, o no es nada, porque no aparece ninguna otra sugerencia).

Cómo genera Google el autocompletado de las búsquedas

Danny Sullivan, Public Liaison of Search en Google, ha publicado un extenso artículo acerca de cómo funcionan las predicciones del buscador de la compañía fundada por Serguéi Brin y Larry Page allá por 1998, hace ya 22 años.

Leer más: Los garajes en los que empezaron Google, Apple, Amazon y Microsoft

Este paso adelante de Google en lo referido a la transparencia de su motor de búsqueda no llega justo ahora por casualidad: a las puertas de las elecciones de Estados Unidos —previstas para celebrarse el próximo día 3 de noviembre—, todas las miradas están puestas en las grandes compañías tecnológicas y su papel en el resultado de las candidaturas —algo que, tal y como ya se vio el año pasado, puede influir en la decisión de voto—.

De dónde vienen las respuestas del autocompletado, por qué aparecen unas u otras y, especialmente, de qué manera garantiza Google que no se muestren sugerencias que el usuario no debería ver, son algunas de las cuestiones que viene a resolver el artículo en cuestión firmado por una de las cabezas visibles de la búsqueda en Google.

Quién (o qué) escribe las sugerencias de autocompletado del buscador de Google

Primero, el autocompletado de Google funciona por repetición: si en internet hay muchas personas que han buscado o están buscando un tema específico, Google utilizará esas consultas para completar las búsquedas relacionadas de los usuarios que vayan llegando de ahí en adelante.

Si comienzas por ejemplo a escribir una búsqueda que empieza por 'Star Trek mejores ', el autocompletado sugerirá búsquedas como 'Star Trek mejores series', 'Star Trek mejores películas' o 'Star Trek mejores episodios', basándose en búsquedas similares y/o populares en relación a ese término que Google ha detectado en los últimos tiempos. También, se tiene en cuenta el número de resultados que hablan sobre dichos temas en esos términos.

Otros factores adicionales como la localización del usuario, el idioma en que se hace la búsqueda o las tendencias de última hora también intervienen en este proceso automatizado de selección.

Leer más: Esto es todo lo que Google sabe de ti gracias a sus aplicaciones y tu despreocupación

En caso de que un equipo de fútbol vaya a jugar un partido importante contra otro en unos días, es muy probable que el autocompletado de esa búsqueda refleje durante los días previos el interés de los usuarios por dicho encuentro. O si un usuario está buscando información sobre viajar a Nueva York, es muy probable que el autocompletado recomiende búsquedas sobre viajes a Nueva York en Navidad, dado que es una fecha del año muy popular para visitar la ciudad.

La pregunta es: ¿qué pasa cuando las tendencias de búsqueda comienzan a virar hacia afirmaciones falsas? ¿El simple hecho de que muchas personas busquen algo lo convierte automáticamente en verdad? Ahí entra en juego la maquinaria de filtrado de Google.

Los filtros que Google utiliza para evitar que el autocompletado muestre lo que el usuario no debería ver

Partiendo de la premisa de que sus recomendaciones no son siempre perfectas, Google es consciente de que puede haber usuarios que interpreten las predicciones del autocompletado como afirmaciones categóricas sobre hechos u opiniones.

No en vano, es la propia compañía la que lleva años invitando a los usuarios a resolver sus consultas sin necesidad de ir más allá del propio buscador: herramientas como la calculadora, el traductor de idiomas o los fragmentos destacados han sido concebidos para dar al usuario una respuesta a su consulta sin necesidad de ir más allá.

Dada esa gran responsabilidad, la compañía de Mountain View utiliza dos mecanismos para tratar de frenar cualquier posible sugerencia de búsqueda que vaya en contra de sus políticas de autocompletar: la inteligencia artificial y la revisión manual.

Leer más: El rol del humano en la era de la inteligencia artificial: esto es lo que opinan los grandes líderes

Primero, existen filtros automatizados que evitan que aparezcan sugerencias de autocompletado que vayan en contra de alguna de las normas del buscador. El sistema detecta y bloquea automáticamente términos y frases que sean violentas, sexualmente explícitas, de odio, despectivas o peligrosas. Este filtro actúa antes de que la sugerencia pase a formar parte de la lista de autocompletar.

En caso de que el primer mecanismo falle, existen equipos humanos que se encargan de retirar aquellas sugerencias de búsqueda que, estando ya en línea, hayan sido marcadas como potencialmente peligrosas. Claro que, para eso, primero es necesario que un usuario denuncie la predicción en cuestión.

Las miradas puestas en las elecciones de Estados Unidos

En otro artículo publicado a comienzos de septiembre, Google hacía otro ejercicio de transparencia detallando la manera en que trabajan para ofrecer la mejor cobertura de las noticias de todo el mundo al mismo tiempo que hacen frente a amenazas como las fake news.

En uno de esos puntos, Google anunciaba que desactivará el autocompletado para aquellas búsquedas que puedan inducir a obtener afirmaciones falsas sobre un candidato o un partido político de las elecciones de Estados Unidos en 2020.

A día de hoy, búsquedas como 'puedes votar por teléfono' ('you can vote by phone' en inglés) o 'no puedes votar por teléfono' ('you can't vote by phone') ya tienen desactivado el autocompletado en el buscador de Google en inglés para evitar que un usuario pueda extraer alguna conclusión errónea sin terminar de realizar su búsqueda. El de los métodos de voto es, a día de hoy, uno de los temas candentes a las puertas de las elecciones americanas.

Jakub Motyka es SEO specialist con más de nueve años de experiencia en buscadores, visibilidad en internet y analítica web.